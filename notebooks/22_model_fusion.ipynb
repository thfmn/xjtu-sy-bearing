{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL-5: Pattern 2 - 2D CNN + Temporal Architecture\n",
    "\n",
    "This notebook demonstrates the Pattern 2 architecture for RUL prediction using:\n",
    "- **STFT Spectrograms**: Time-frequency representation of vibration signals\n",
    "- **2D CNN Backbone**: Spatial feature extraction from spectrograms\n",
    "- **Late Fusion**: Combining horizontal and vertical channel embeddings\n",
    "- **Temporal Aggregator**: LSTM or Transformer for sequence modeling\n",
    "- **RUL Head**: Non-negative RUL prediction (optional uncertainty)\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "Spectrogram (128, 128, 2)\n",
    "    ↓\n",
    "DualChannelCNN2DBackbone (per-channel or shared weights)\n",
    "    ↓\n",
    "LateFusion (concat, add, or weighted)\n",
    "    ↓\n",
    "TemporalAggregator (LSTM v1 or Transformer v2)\n",
    "    ↓\n",
    "RULHead (optional uncertainty via Gaussian output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** This notebook documents exploratory model development. ",
    "The architectures investigated here informed the final benchmark models ",
    "but are not part of the production evaluation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Generate Spectrograms\n",
    "\n",
    "First, we load the raw bearing data and generate spectrograms using STFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.loader import XJTUBearingLoader\n",
    "from src.data.rul_labels import generate_rul_labels, RULStrategy\n",
    "from src.features.stft import extract_spectrogram\n",
    "\n",
    "# Initialize loader\n",
    "loader = XJTUBearingLoader()\n",
    "metadata = loader.get_metadata()\n",
    "\n",
    "print(f\"Dataset overview:\")\n",
    "print(f\"  Conditions: {list(metadata.keys())}\")\n",
    "print(f\"  Total bearings: {sum(len(c) for c in metadata.values())}\")\n",
    "print(f\"  Sample rate: 25.6 kHz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for one condition (35Hz12kN) for demonstration\n",
    "condition = '35Hz12kN'\n",
    "bearings = metadata[condition]\n",
    "\n",
    "print(f\"Loading data for condition: {condition}\")\n",
    "print(f\"Bearings: {list(bearings.keys())}\")\n",
    "\n",
    "# Load first bearing to get file count\n",
    "bearing_id = 'Bearing1_1'\n",
    "signals, files = loader.load_bearing(condition, bearing_id)\n",
    "print(f\"\\n{bearing_id}: {len(files)} files, signal shape per file: {signals[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spectrograms for a subset of the data\n",
    "n_samples = min(50, len(signals))  # Limit for demo\n",
    "\n",
    "print(f\"Generating {n_samples} spectrograms...\")\n",
    "spectrograms = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    spec = extract_spectrogram(signals[i], sampling_rate=25600.0)\n",
    "    spectrograms.append(spec)\n",
    "\n",
    "spectrograms = np.stack(spectrograms)\n",
    "print(f\"Spectrograms shape: {spectrograms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RUL labels\n",
    "rul_labels = generate_rul_labels(\n",
    "    total_files=len(files),\n",
    "    strategy=RULStrategy.PIECEWISE_LINEAR,\n",
    "    max_rul=125\n",
    ")\n",
    "\n",
    "# Get labels for our subset\n",
    "y_subset = rul_labels[:n_samples].astype(np.float32).reshape(-1, 1)\n",
    "print(f\"RUL labels shape: {y_subset.shape}\")\n",
    "print(f\"RUL range: {y_subset.min():.1f} - {y_subset.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrograms at different lifecycle stages\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Indices: early, mid, late\n",
    "indices = [0, n_samples // 2, n_samples - 1]\n",
    "titles = ['Early (Healthy)', 'Mid (Degrading)', 'Late (Near Failure)']\n",
    "\n",
    "for col, (idx, title) in enumerate(zip(indices, titles)):\n",
    "    # Horizontal channel\n",
    "    axes[0, col].imshow(spectrograms[idx, :, :, 0], aspect='auto', origin='lower', cmap='viridis')\n",
    "    axes[0, col].set_title(f'{title} - Horizontal\\nRUL: {y_subset[idx, 0]:.1f}')\n",
    "    axes[0, col].set_xlabel('Time Frame')\n",
    "    axes[0, col].set_ylabel('Mel Bin')\n",
    "    \n",
    "    # Vertical channel\n",
    "    axes[1, col].imshow(spectrograms[idx, :, :, 1], aspect='auto', origin='lower', cmap='viridis')\n",
    "    axes[1, col].set_title(f'{title} - Vertical')\n",
    "    axes[1, col].set_xlabel('Time Frame')\n",
    "    axes[1, col].set_ylabel('Mel Bin')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/models/pattern2_spectrograms.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build and Compare Pattern 2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.pattern2 import (\n",
    "    create_pattern2_lstm,\n",
    "    create_pattern2_transformer,\n",
    "    create_simple_pattern2,\n",
    "    create_pattern2_with_uncertainty,\n",
    "    print_model_summary,\n",
    ")\n",
    "\n",
    "# Create model variants\n",
    "print(\"=\" * 60)\n",
    "print(\"Pattern 2 Model Variants\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# LSTM variant\n",
    "print(\"\\n1. LSTM Aggregator (v1):\")\n",
    "model_lstm = create_pattern2_lstm()\n",
    "print_model_summary(model_lstm)\n",
    "\n",
    "# Transformer variant\n",
    "print(\"\\n2. Transformer Aggregator (v2):\")\n",
    "model_transformer = create_pattern2_transformer()\n",
    "print_model_summary(model_transformer)\n",
    "\n",
    "# Simple variant (no temporal aggregation)\n",
    "print(\"\\n3. Simple (No Temporal Aggregation):\")\n",
    "model_simple = create_simple_pattern2()\n",
    "print_model_summary(model_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Pattern 2 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.config import TrainingConfig, compile_model, build_callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    spectrograms, y_subset, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile model\n",
    "model = create_pattern2_lstm()\n",
    "\n",
    "# Training configuration\n",
    "config = TrainingConfig(\n",
    "    epochs=30,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "compile_model(model, config)\n",
    "\n",
    "# Build callbacks (simplified for demo)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=config.epochs,\n",
    "    batch_size=config.batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (Huber)')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# MAE\n",
    "axes[1].plot(history.history['mae'], label='Train MAE')\n",
    "axes[1].plot(history.history['val_mae'], label='Val MAE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_title('Training and Validation MAE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/models/pattern2_training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.training.metrics import rmse, mae, phm08_score\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train, verbose=0)\n",
    "y_pred_val = model.predict(X_val, verbose=0)\n",
    "\n",
    "# Compute metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(f\"  RMSE: {rmse(y_train.flatten(), y_pred_train.flatten()):.4f}\")\n",
    "print(f\"  MAE:  {mae(y_train.flatten(), y_pred_train.flatten()):.4f}\")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(f\"  RMSE: {rmse(y_val.flatten(), y_pred_val.flatten()):.4f}\")\n",
    "print(f\"  MAE:  {mae(y_val.flatten(), y_pred_val.flatten()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training set\n",
    "axes[0].scatter(y_train, y_pred_train, alpha=0.7, label='Predictions')\n",
    "axes[0].plot([0, 130], [0, 130], 'r--', label='Perfect')\n",
    "axes[0].set_xlabel('True RUL')\n",
    "axes[0].set_ylabel('Predicted RUL')\n",
    "axes[0].set_title('Training Set: Predicted vs True RUL')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Validation set\n",
    "axes[1].scatter(y_val, y_pred_val, alpha=0.7, label='Predictions')\n",
    "axes[1].plot([0, 130], [0, 130], 'r--', label='Perfect')\n",
    "axes[1].set_xlabel('True RUL')\n",
    "axes[1].set_ylabel('Predicted RUL')\n",
    "axes[1].set_title('Validation Set: Predicted vs True RUL')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/models/pattern2_predictions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model with Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with uncertainty output\n",
    "model_unc = create_pattern2_with_uncertainty()\n",
    "print(\"Pattern 2 with Uncertainty:\")\n",
    "print_model_summary(model_unc)\n",
    "\n",
    "# Note: Training with uncertainty requires custom loss function\n",
    "# For now, just demonstrate the model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test uncertainty output\n",
    "mean_pred, var_pred = model_unc.predict(X_val[:5], verbose=0)\n",
    "std_pred = np.sqrt(var_pred)\n",
    "\n",
    "print(\"Uncertainty Output Example:\")\n",
    "print(f\"{'True RUL':<10} {'Mean':<10} {'Std':<10} {'95% CI':>20}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(5):\n",
    "    ci_low = mean_pred[i, 0] - 1.96 * std_pred[i, 0]\n",
    "    ci_high = mean_pred[i, 0] + 1.96 * std_pred[i, 0]\n",
    "    print(f\"{y_val[i, 0]:<10.1f} {mean_pred[i, 0]:<10.4f} {std_pred[i, 0]:<10.4f} [{ci_low:.2f}, {ci_high:.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "### Model Comparison\n",
    "\n",
    "| Model | Parameters | Input Shape | Notes |\n",
    "|-------|------------|-------------|-------|\n",
    "| Pattern 2 LSTM | ~693K | (128, 128, 2) | Bidirectional LSTM aggregator |\n",
    "| Pattern 2 Transformer | ~3.8M | (128, 128, 2) | 2-layer Transformer aggregator |\n",
    "| Pattern 2 Simple | ~423K | (128, 128, 2) | No temporal aggregation |\n",
    "| Pattern 2 Uncertainty | ~694K | (128, 128, 2) | Outputs mean + variance |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **2D CNN + Temporal architecture** successfully processes spectrograms for RUL prediction\n",
    "2. **Late fusion** effectively combines horizontal and vertical channel embeddings\n",
    "3. **LSTM and Transformer aggregators** both work for sequence modeling\n",
    "4. **Uncertainty quantification** provides confidence intervals for predictions\n",
    "5. Model trains and loss decreases, indicating learning is occurring\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Train on full dataset with proper cross-validation\n",
    "2. Compare with Pattern 1 (TCN-Transformer) architecture\n",
    "3. Implement sequence-of-spectrograms mode for temporal context\n",
    "4. Add CWT scalogram frontend (FEAT-8) for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "import os\n",
    "os.makedirs('../outputs/models', exist_ok=True)\n",
    "model.save('../outputs/models/pattern2_lstm_demo.keras')\n",
    "print(\"Model saved to outputs/models/pattern2_lstm_demo.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
