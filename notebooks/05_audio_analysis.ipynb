{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# EDA-4: Audio Artifacts Analysis\n",
    "\n",
    "**Sonification of Bearing Vibration Signals for XJTU-SY Dataset**\n",
    "\n",
    "This notebook explores bearing health through auditory analysis. Since the vibration signals are sampled at 25.6kHz (already in the audible range), we can convert them directly to audio files to \"hear\" bearing degradation.\n",
    "\n",
    "## Key Features\n",
    "1. **Signal-to-Audio Conversion**: Convert vibration signals to WAV files\n",
    "2. **Resampling**: Upsample to 44.1kHz for standard audio playback\n",
    "3. **Lifecycle Audio Generation**: Create audio at healthy, degrading, and failed states\n",
    "4. **Audio Comparison Widget**: Interactive playback for comparing bearing health states\n",
    "5. **Spectrogram Visualization**: Visual+auditory correlation\n",
    "\n",
    "## Why Sonification?\n",
    "- Humans are excellent at detecting subtle patterns in sound\n",
    "- Degradation often manifests as grinding, clicking, or roughness\n",
    "- Auditory analysis complements visual spectrograms\n",
    "- Technicians often use stethoscopes for bearing inspection\n",
    "\n",
    "## Dataset Parameters\n",
    "- **Sampling Rate**: 25.6 kHz (audible range: 20 Hz - 12.8 kHz)\n",
    "- **Duration per file**: 32,768 samples = 1.28 seconds\n",
    "- **Channels**: Horizontal and Vertical vibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display, HTML\n",
    "import ipywidgets as widgets\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project modules\n",
    "from src.data.loader import XJTUBearingLoader, SAMPLING_RATE\n",
    "from src.utils.audio import (\n",
    "    resample_signal,\n",
    "    normalize_audio,\n",
    "    signal_to_wav,\n",
    "    convert_vibration_to_audio,\n",
    "    AudioConfig,\n",
    "    SOURCE_SAMPLE_RATE,\n",
    "    TARGET_SAMPLE_RATE,\n",
    ")\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [14, 5]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Output directory for audio files\n",
    "AUDIO_OUTPUT_DIR = Path('../outputs/audio')\n",
    "AUDIO_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Libraries loaded successfully!')\n",
    "print(f'Source Sampling Rate: {SOURCE_SAMPLE_RATE:,} Hz')\n",
    "print(f'Target Sampling Rate: {TARGET_SAMPLE_RATE:,} Hz')\n",
    "print(f'Audio Output Directory: {AUDIO_OUTPUT_DIR.absolute()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = XJTUBearingLoader(data_root='../assets/Data/XJTU-SY_Bearing_Datasets')\n",
    "metadata = loader.get_metadata()\n",
    "\n",
    "print(f'\\nDataset Overview:')\n",
    "print(f'Conditions: {list(metadata.keys())}')\n",
    "for condition, bearings in metadata.items():\n",
    "    total_files = sum(len(files) for files in bearings.values())\n",
    "    print(f'  {condition}: {len(bearings)} bearings, {total_files} total files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Understanding the Signal as Audio\n",
    "\n",
    "Before converting to audio, let's understand what we're working with. The vibration signal at 25.6kHz captures frequencies from 0 to 12.8kHz (Nyquist), which is well within the human hearing range (20Hz - 20kHz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample signal\n",
    "sample_condition = '40Hz10kN'\n",
    "sample_bearing = 'Bearing3_2'\n",
    "\n",
    "# Load all files for this bearing\n",
    "signals, filenames = loader.load_bearing(sample_condition, sample_bearing)\n",
    "num_files = len(filenames)\n",
    "\n",
    "print(f'Loaded {num_files} files from {sample_bearing} ({sample_condition})')\n",
    "print(f'Signal shape per file: {signals[0].shape}')\n",
    "print(f'Duration per file: {signals[0].shape[0] / SAMPLING_RATE * 1000:.1f} ms')\n",
    "\n",
    "# Audio properties\n",
    "duration_sec = signals[0].shape[0] / SAMPLING_RATE\n",
    "nyquist = SAMPLING_RATE / 2\n",
    "\n",
    "print(f'\\nAudio Properties:')\n",
    "print(f'  Duration: {duration_sec:.3f} seconds')\n",
    "print(f'  Nyquist Frequency: {nyquist:,.0f} Hz')\n",
    "print(f'  Audible Range: ~20 Hz to {min(nyquist, 20000):,.0f} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize waveform and spectrogram for healthy vs failed states\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "# Define lifecycle stages\n",
    "stages = {\n",
    "    'Healthy (5%)': int(num_files * 0.05),\n",
    "    'Degrading (50%)': int(num_files * 0.50),\n",
    "    'Failed (95%)': int(num_files * 0.95)\n",
    "}\n",
    "\n",
    "for col, (stage_name, file_idx) in enumerate(stages.items()):\n",
    "    sig = signals[file_idx][:, 0]  # Horizontal channel\n",
    "    time_ms = np.arange(len(sig)) / SAMPLING_RATE * 1000\n",
    "    \n",
    "    # Waveform\n",
    "    axes[0, col].plot(time_ms, sig, linewidth=0.5, color='#3498db')\n",
    "    axes[0, col].set_title(f'{stage_name}', fontsize=12, fontweight='bold')\n",
    "    axes[0, col].set_xlabel('Time (ms)')\n",
    "    axes[0, col].set_ylabel('Amplitude')\n",
    "    axes[0, col].set_xlim(0, time_ms[-1])\n",
    "    \n",
    "    # Add RMS annotation\n",
    "    rms = np.sqrt(np.mean(sig**2))\n",
    "    axes[0, col].annotate(f'RMS: {rms:.3f}', xy=(0.02, 0.98), xycoords='axes fraction',\n",
    "                          fontsize=10, va='top', ha='left',\n",
    "                          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Spectrogram\n",
    "    f, t, Sxx = signal.spectrogram(sig, fs=SAMPLING_RATE, nperseg=512, noverlap=384)\n",
    "    Sxx_db = 10 * np.log10(Sxx + 1e-10)\n",
    "    \n",
    "    im = axes[1, col].pcolormesh(t*1000, f/1000, Sxx_db, shading='gouraud', cmap='inferno')\n",
    "    axes[1, col].set_xlabel('Time (ms)')\n",
    "    axes[1, col].set_ylabel('Frequency (kHz)')\n",
    "    axes[1, col].set_ylim(0, 6)  # Focus on 0-6 kHz\n",
    "\n",
    "plt.suptitle(f'Bearing {sample_bearing}: Waveform and Spectrogram at Different Lifecycle Stages',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Converting Vibration Signals to Audio\n",
    "\n",
    "We'll resample from 25.6kHz to 44.1kHz (CD-quality audio) to ensure compatibility with standard audio players. The `src/utils/audio.py` module handles this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate resampling process\n",
    "healthy_sig = signals[stages['Healthy (5%)']][:, 0]\n",
    "failed_sig = signals[stages['Failed (95%)']][:, 0]\n",
    "\n",
    "print(f'Original signal: {len(healthy_sig):,} samples @ {SOURCE_SAMPLE_RATE:,} Hz')\n",
    "\n",
    "# Resample to 44.1kHz\n",
    "healthy_resampled = resample_signal(healthy_sig)\n",
    "failed_resampled = resample_signal(failed_sig)\n",
    "\n",
    "print(f'Resampled signal: {len(healthy_resampled):,} samples @ {TARGET_SAMPLE_RATE:,} Hz')\n",
    "print(f'Duration unchanged: {len(healthy_resampled)/TARGET_SAMPLE_RATE:.3f} s')\n",
    "\n",
    "# Normalize for audio playback\n",
    "healthy_audio = normalize_audio(healthy_resampled)\n",
    "failed_audio = normalize_audio(failed_resampled)\n",
    "\n",
    "print(f'\\nAmplitude range (healthy): [{healthy_audio.min():.3f}, {healthy_audio.max():.3f}]')\n",
    "print(f'Amplitude range (failed): [{failed_audio.min():.3f}, {failed_audio.max():.3f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify resampling preserves signal characteristics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "\n",
    "# Time domain comparison\n",
    "time_orig = np.arange(len(healthy_sig)) / SOURCE_SAMPLE_RATE * 1000\n",
    "time_resamp = np.arange(len(healthy_resampled)) / TARGET_SAMPLE_RATE * 1000\n",
    "\n",
    "# Show first 10ms for detail\n",
    "limit_orig = int(0.01 * SOURCE_SAMPLE_RATE)\n",
    "limit_resamp = int(0.01 * TARGET_SAMPLE_RATE)\n",
    "\n",
    "axes[0, 0].plot(time_orig[:limit_orig], healthy_sig[:limit_orig], label='Original (25.6kHz)', alpha=0.8)\n",
    "axes[0, 0].plot(time_resamp[:limit_resamp], healthy_resampled[:limit_resamp], label='Resampled (44.1kHz)', alpha=0.8)\n",
    "axes[0, 0].set_title('Healthy: Time Domain (First 10ms)')\n",
    "axes[0, 0].set_xlabel('Time (ms)')\n",
    "axes[0, 0].set_ylabel('Amplitude')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(time_orig[:limit_orig], failed_sig[:limit_orig], label='Original (25.6kHz)', alpha=0.8)\n",
    "axes[0, 1].plot(time_resamp[:limit_resamp], failed_resampled[:limit_resamp], label='Resampled (44.1kHz)', alpha=0.8)\n",
    "axes[0, 1].set_title('Failed: Time Domain (First 10ms)')\n",
    "axes[0, 1].set_xlabel('Time (ms)')\n",
    "axes[0, 1].set_ylabel('Amplitude')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Frequency domain comparison (PSD)\n",
    "f_orig, psd_orig = signal.welch(healthy_sig, fs=SOURCE_SAMPLE_RATE, nperseg=2048)\n",
    "f_resamp, psd_resamp = signal.welch(healthy_resampled, fs=TARGET_SAMPLE_RATE, nperseg=2048)\n",
    "\n",
    "axes[1, 0].semilogy(f_orig/1000, psd_orig, label='Original (25.6kHz)', alpha=0.8)\n",
    "axes[1, 0].semilogy(f_resamp/1000, psd_resamp, label='Resampled (44.1kHz)', alpha=0.8)\n",
    "axes[1, 0].set_title('Healthy: Power Spectral Density')\n",
    "axes[1, 0].set_xlabel('Frequency (kHz)')\n",
    "axes[1, 0].set_ylabel('PSD')\n",
    "axes[1, 0].set_xlim(0, 12)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].axvline(x=12.8, color='red', linestyle='--', alpha=0.5, label='Original Nyquist')\n",
    "\n",
    "f_orig_f, psd_orig_f = signal.welch(failed_sig, fs=SOURCE_SAMPLE_RATE, nperseg=2048)\n",
    "f_resamp_f, psd_resamp_f = signal.welch(failed_resampled, fs=TARGET_SAMPLE_RATE, nperseg=2048)\n",
    "\n",
    "axes[1, 1].semilogy(f_orig_f/1000, psd_orig_f, label='Original (25.6kHz)', alpha=0.8)\n",
    "axes[1, 1].semilogy(f_resamp_f/1000, psd_resamp_f, label='Resampled (44.1kHz)', alpha=0.8)\n",
    "axes[1, 1].set_title('Failed: Power Spectral Density')\n",
    "axes[1, 1].set_xlabel('Frequency (kHz)')\n",
    "axes[1, 1].set_ylabel('PSD')\n",
    "axes[1, 1].set_xlim(0, 12)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].axvline(x=12.8, color='red', linestyle='--', alpha=0.5, label='Original Nyquist')\n",
    "\n",
    "plt.suptitle('Resampling Verification: Signal Characteristics Preserved', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Audio Playback: Healthy vs Degrading vs Failed\n",
    "\n",
    "Now let's listen to the bearing at different lifecycle stages. Use headphones for best experience!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display audio for each lifecycle stage\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Bearing: {sample_bearing} ({sample_condition})\")\n",
    "print(f\"Use headphones for the best listening experience!\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for stage_name, file_idx in stages.items():\n",
    "    sig = signals[file_idx][:, 0]  # Horizontal channel\n",
    "    \n",
    "    # Resample and normalize\n",
    "    resampled = resample_signal(sig)\n",
    "    audio_data = normalize_audio(resampled)\n",
    "    \n",
    "    # Calculate RMS for reference\n",
    "    rms = np.sqrt(np.mean(sig**2))\n",
    "    \n",
    "    print(f\"\\n{stage_name} (File {file_idx+1}/{num_files})\")\n",
    "    print(f\"  RMS: {rms:.4f}\")\n",
    "    print(f\"  Duration: {len(audio_data)/TARGET_SAMPLE_RATE:.2f} seconds\")\n",
    "    \n",
    "    # Display audio player\n",
    "    display(Audio(data=audio_data, rate=TARGET_SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "### What to Listen For\n",
    "\n",
    "- **Healthy**: Relatively smooth, consistent tone with low-frequency hum from rotation\n",
    "- **Degrading**: May hear occasional clicks or increased roughness\n",
    "- **Failed**: Loud grinding, clicking, or harsh metallic sounds; much louder overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Save WAV Files for Multiple Bearings\n",
    "\n",
    "Generate audio files for all bearings at key lifecycle stages for offline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_for_bearing(loader, condition, bearing_id, output_dir, \n",
    "                                lifecycle_pcts=[0, 50, 100], channel='horizontal'):\n",
    "    \"\"\"\n",
    "    Generate WAV files for a bearing at specified lifecycle percentages.\n",
    "    \n",
    "    Args:\n",
    "        loader: XJTUBearingLoader instance\n",
    "        condition: Operating condition string\n",
    "        bearing_id: Bearing identifier\n",
    "        output_dir: Directory to save WAV files\n",
    "        lifecycle_pcts: List of lifecycle percentages (0=healthy, 100=failed)\n",
    "        channel: 'horizontal', 'vertical', or 'both'\n",
    "    \n",
    "    Returns:\n",
    "        List of generated file paths\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    signals, filenames = loader.load_bearing(condition, bearing_id)\n",
    "    num_files = len(filenames)\n",
    "    \n",
    "    generated_files = []\n",
    "    \n",
    "    for pct in lifecycle_pcts:\n",
    "        file_idx = min(int(num_files * pct / 100), num_files - 1)\n",
    "        sig = signals[file_idx]\n",
    "        \n",
    "        # Determine stage name\n",
    "        if pct <= 10:\n",
    "            stage = 'healthy'\n",
    "        elif pct >= 90:\n",
    "            stage = 'failed'\n",
    "        else:\n",
    "            stage = 'degrading'\n",
    "        \n",
    "        # Generate filename\n",
    "        filename = f\"{bearing_id}_{stage}_{pct}pct_{channel}.wav\"\n",
    "        output_path = output_dir / filename\n",
    "        \n",
    "        # Convert to audio\n",
    "        convert_vibration_to_audio(sig, output_path, channel=channel)\n",
    "        generated_files.append(output_path)\n",
    "    \n",
    "    return generated_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audio files for a few representative bearings\n",
    "representative_bearings = [\n",
    "    ('35Hz12kN', 'Bearing1_1'),\n",
    "    ('37.5Hz11kN', 'Bearing2_1'),\n",
    "    ('40Hz10kN', 'Bearing3_2'),\n",
    "]\n",
    "\n",
    "lifecycle_stages = [0, 25, 50, 75, 100]  # 5 stages from healthy to failed\n",
    "\n",
    "all_generated_files = []\n",
    "\n",
    "print(\"Generating audio files...\\n\")\n",
    "\n",
    "for condition, bearing_id in representative_bearings:\n",
    "    print(f\"Processing {bearing_id} ({condition})...\")\n",
    "    \n",
    "    files = generate_audio_for_bearing(\n",
    "        loader, condition, bearing_id,\n",
    "        output_dir=AUDIO_OUTPUT_DIR,\n",
    "        lifecycle_pcts=lifecycle_stages,\n",
    "        channel='horizontal'\n",
    "    )\n",
    "    \n",
    "    all_generated_files.extend(files)\n",
    "    print(f\"  Generated {len(files)} files\")\n",
    "\n",
    "print(f\"\\nTotal files generated: {len(all_generated_files)}\")\n",
    "print(f\"Output directory: {AUDIO_OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59kumu4uj9q",
   "source": "### 4.1 Generate Audio for ALL 15 Bearings\n\nNow let's generate audio files for **all 15 bearings** at three key lifecycle stages (healthy, degrading, failed) to meet the acceptance criteria.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4jyiy1xe1l4",
   "source": "# Generate audio files for ALL 15 bearings at key lifecycle stages\n# This satisfies EDA-4 acceptance criteria: \"At least 3 lifecycle stages per bearing have audio files generated\"\n\n# Get unique condition-bearing pairs from metadata DataFrame\nunique_bearings = metadata.groupby(['condition', 'bearing_id']).size().reset_index(name='count')\nall_bearings = list(zip(unique_bearings['condition'], unique_bearings['bearing_id']))\n\nprint(f\"Generating audio for {len(all_bearings)} bearings...\")\nprint(\"Lifecycle stages: 0% (healthy), 50% (degrading), 100% (failed)\")\nprint(\"=\"*70)\n\n# Key lifecycle stages\nkey_stages = [0, 50, 100]  # healthy, degrading, failed\n\ntotal_files_generated = 0\nall_audio_files = []\n\nfor i, (condition, bearing_id) in enumerate(all_bearings):\n    print(f\"\\n[{i+1}/{len(all_bearings)}] Processing {bearing_id} ({condition})...\")\n    \n    # Create output directory for this bearing\n    bearing_output_dir = AUDIO_OUTPUT_DIR / condition / bearing_id\n    bearing_output_dir.mkdir(parents=True, exist_ok=True)\n    \n    try:\n        # Load bearing data\n        signals, filenames = loader.load_bearing(condition, bearing_id)\n        num_files = len(filenames)\n        \n        for pct in key_stages:\n            file_idx = min(int(num_files * pct // 100), num_files - 1)\n            sig = signals[file_idx]\n            \n            # Determine stage name\n            if pct == 0:\n                stage = 'healthy'\n            elif pct == 100:\n                stage = 'failed'\n            else:\n                stage = 'degrading'\n            \n            # Generate for horizontal channel\n            filename = f\"{bearing_id}_{stage}_{pct}pct_h.wav\"\n            output_path = bearing_output_dir / filename\n            \n            # Skip if already exists\n            if output_path.exists():\n                print(f\"  Skipping {filename} (already exists)\")\n                all_audio_files.append(output_path)\n                continue\n            \n            # Convert to audio (horizontal channel)\n            h_signal = sig[:, 0]\n            resampled = resample_signal(h_signal)\n            audio_data = normalize_audio(resampled)\n            signal_to_wav(audio_data, output_path, sample_rate=TARGET_SAMPLE_RATE)\n            \n            all_audio_files.append(output_path)\n            total_files_generated += 1\n            print(f\"  Generated: {filename}\")\n            \n    except Exception as e:\n        print(f\"  ERROR: {e}\")\n        continue\n\nprint(f\"\\n{'='*70}\")\nprint(f\"COMPLETE: Generated {total_files_generated} new audio files\")\nprint(f\"Total audio files across all bearings: {len(all_audio_files)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated files\n",
    "print(\"Generated Audio Files:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for f in sorted(AUDIO_OUTPUT_DIR.glob('*.wav')):\n",
    "    # Get file size\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  {f.name:50} ({size_kb:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": "---\n\n## 5. Interactive Audio Comparison Widget\n\nThis widget allows **side-by-side comparison** of bearing audio at different lifecycle stages:\n- **Healthy (0%)**: Early life, minimal degradation\n- **Degrading (50%)**: Mid-life, progressive wear\n- **Failed (100%)**: End-of-life, severe damage\n\nSelect any bearing and channel to instantly compare the audio signatures. Use headphones for the best experience!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# AUDIO COMPARISON WIDGET\n# =============================================================================\n# This widget allows side-by-side comparison of bearing audio at different\n# lifecycle stages (Healthy, Degrading, Failed) for any selected bearing.\n\nfrom IPython.display import Audio, display, HTML, clear_output\nimport ipywidgets as widgets\n\n# Build dropdown options from available bearings\nbearing_options = []\nfor condition, bearings in metadata.items():\n    for bearing_id in bearings.keys():\n        bearing_options.append(f\"{condition}/{bearing_id}\")\n\n# ============ COMPARISON WIDGET: Side-by-Side Audio Playback ============\n\nclass AudioComparisonWidget:\n    \"\"\"\n    Interactive widget for comparing bearing audio at different lifecycle stages.\n    Displays Healthy (0%), Degrading (50%), and Failed (100%) audio side-by-side.\n    \"\"\"\n    \n    def __init__(self, loader, metadata):\n        self.loader = loader\n        self.metadata = metadata\n        \n        # Build bearing options\n        self.bearing_options = []\n        for condition, bearings in metadata.items():\n            for bearing_id in bearings.keys():\n                self.bearing_options.append(f\"{condition}/{bearing_id}\")\n        \n        # Create widgets\n        self.bearing_dropdown = widgets.Dropdown(\n            options=self.bearing_options,\n            value='40Hz10kN/Bearing3_2',\n            description='Bearing:',\n            style={'description_width': '80px'},\n            layout=widgets.Layout(width='300px')\n        )\n        \n        self.channel_dropdown = widgets.Dropdown(\n            options=['horizontal', 'vertical'],\n            value='horizontal',\n            description='Channel:',\n            style={'description_width': '80px'},\n            layout=widgets.Layout(width='200px')\n        )\n        \n        self.compare_button = widgets.Button(\n            description='Compare Audio',\n            button_style='primary',\n            icon='play',\n            layout=widgets.Layout(width='150px')\n        )\n        \n        self.output_area = widgets.Output()\n        \n        # Connect button to callback\n        self.compare_button.on_click(self._on_compare_click)\n        \n    def _on_compare_click(self, btn):\n        \"\"\"Generate comparison display when button is clicked.\"\"\"\n        self.display_comparison(self.bearing_dropdown.value, self.channel_dropdown.value)\n    \n    def display_comparison(self, bearing_str, channel):\n        \"\"\"Display audio comparison for selected bearing.\"\"\"\n        with self.output_area:\n            clear_output(wait=True)\n            \n            # Parse bearing string\n            condition, bearing_id = bearing_str.split('/')\n            \n            # Load bearing data\n            try:\n                signals, filenames = self.loader.load_bearing(condition, bearing_id)\n            except Exception as e:\n                display(HTML(f\"<p style='color:red'>Error loading bearing: {e}</p>\"))\n                return\n                \n            num_files = len(filenames)\n            channel_idx = 0 if channel == 'horizontal' else 1\n            \n            # Define lifecycle stages\n            stages = [\n                ('Healthy', 0, '#27ae60'),      # Green\n                ('Degrading', 50, '#f39c12'),   # Orange\n                ('Failed', 100, '#e74c3c'),     # Red\n            ]\n            \n            # Header\n            display(HTML(f\"\"\"\n            <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n                        padding: 15px; border-radius: 10px; margin-bottom: 15px; color: white;\">\n                <h2 style=\"margin:0; color:white;\">ðŸ”Š Audio Comparison: {bearing_id}</h2>\n                <p style=\"margin:5px 0 0 0; opacity:0.9;\">\n                    Condition: {condition} | Channel: {channel.title()} | Total Files: {num_files}\n                </p>\n            </div>\n            \"\"\"))\n            \n            # Create comparison table\n            display(HTML(\"\"\"\n            <style>\n                .audio-card { \n                    border: 2px solid #ddd; \n                    border-radius: 10px; \n                    padding: 15px; \n                    margin: 10px 0;\n                    background: white;\n                    box-shadow: 0 2px 5px rgba(0,0,0,0.1);\n                }\n                .audio-card h3 { margin: 0 0 10px 0; }\n                .audio-stats { \n                    display: flex; \n                    gap: 20px; \n                    margin-top: 10px;\n                    flex-wrap: wrap;\n                }\n                .stat-item { \n                    background: #f8f9fa; \n                    padding: 5px 10px; \n                    border-radius: 5px;\n                    font-size: 0.9em;\n                }\n            </style>\n            \"\"\"))\n            \n            # Generate audio for each stage\n            for stage_name, pct, color in stages:\n                file_idx = min(int(num_files * pct / 100), num_files - 1)\n                sig = signals[file_idx][:, channel_idx]\n                \n                # Compute statistics\n                rms = np.sqrt(np.mean(sig**2))\n                peak = np.max(np.abs(sig))\n                crest_factor = peak / rms if rms > 0 else 0\n                \n                # Resample and normalize\n                resampled = resample_signal(sig)\n                audio_data = normalize_audio(resampled)\n                \n                # Display card\n                display(HTML(f\"\"\"\n                <div class=\"audio-card\" style=\"border-left: 5px solid {color};\">\n                    <h3 style=\"color: {color};\">\n                        {'ðŸŸ¢' if pct == 0 else 'ðŸŸ ' if pct == 50 else 'ðŸ”´'} {stage_name} ({pct}% Lifecycle)\n                    </h3>\n                    <p style=\"margin:5px 0; color:#666;\">\n                        File: {filenames[file_idx]} (#{file_idx + 1} of {num_files})\n                    </p>\n                    <div class=\"audio-stats\">\n                        <span class=\"stat-item\">RMS: {rms:.4f}</span>\n                        <span class=\"stat-item\">Peak: {peak:.4f}</span>\n                        <span class=\"stat-item\">Crest Factor: {crest_factor:.2f}</span>\n                    </div>\n                </div>\n                \"\"\"))\n                \n                # Display audio player\n                display(Audio(data=audio_data, rate=TARGET_SAMPLE_RATE))\n            \n            # Add listening tips\n            display(HTML(\"\"\"\n            <div style=\"background: #f0f8ff; padding: 15px; border-radius: 10px; margin-top: 15px; \n                        border-left: 4px solid #3498db;\">\n                <h4 style=\"margin:0 0 10px 0; color:#2980b9;\">ðŸŽ§ Listening Tips</h4>\n                <ul style=\"margin:0; padding-left:20px; color:#34495e;\">\n                    <li><strong>Healthy:</strong> Smooth, consistent tone with low-frequency hum</li>\n                    <li><strong>Degrading:</strong> May hear occasional clicks or increased roughness</li>\n                    <li><strong>Failed:</strong> Loud grinding, clicking, or harsh metallic sounds</li>\n                </ul>\n                <p style=\"margin:10px 0 0 0; font-style:italic; color:#7f8c8d;\">\n                    Use headphones for the best listening experience!\n                </p>\n            </div>\n            \"\"\"))\n    \n    def show(self):\n        \"\"\"Display the complete widget interface.\"\"\"\n        # Title\n        title = widgets.HTML(\"\"\"\n        <h3 style=\"background: #2c3e50; color: white; padding: 10px 15px; \n                   border-radius: 5px; margin-bottom: 10px;\">\n            ðŸŽµ Audio Comparison Widget\n        </h3>\n        <p style=\"color: #666; margin-bottom: 15px;\">\n            Select a bearing and click \"Compare Audio\" to hear Healthy, Degrading, and Failed states side-by-side.\n        </p>\n        \"\"\")\n        \n        # Controls layout\n        controls = widgets.HBox([\n            self.bearing_dropdown,\n            self.channel_dropdown,\n            self.compare_button\n        ], layout=widgets.Layout(gap='10px'))\n        \n        # Full layout\n        layout = widgets.VBox([\n            title,\n            controls,\n            self.output_area\n        ])\n        \n        display(layout)\n        \n        # Auto-load first comparison\n        self.display_comparison(self.bearing_dropdown.value, self.channel_dropdown.value)\n\n\n# Create and display the comparison widget\ncomparison_widget = AudioComparisonWidget(loader, metadata)\ncomparison_widget.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Audio Feature Analysis: What Makes Failed Bearings Sound Different?\n",
    "\n",
    "Let's analyze the audio characteristics that distinguish healthy from failed bearings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_audio_features(signal_data):\n",
    "    \"\"\"Compute audio-relevant features from vibration signal.\"\"\"\n",
    "    # Time domain\n",
    "    rms = np.sqrt(np.mean(signal_data**2))\n",
    "    peak = np.max(np.abs(signal_data))\n",
    "    crest_factor = peak / rms if rms > 0 else 0\n",
    "    \n",
    "    # Zero crossing rate (indicates roughness)\n",
    "    zero_crossings = np.sum(np.diff(np.signbit(signal_data).astype(int)) != 0)\n",
    "    zcr = zero_crossings / len(signal_data)\n",
    "    \n",
    "    # Spectral features\n",
    "    freqs, psd = signal.welch(signal_data, fs=SAMPLING_RATE, nperseg=2048)\n",
    "    psd_normalized = psd / np.sum(psd)\n",
    "    \n",
    "    # Spectral centroid (perceived brightness)\n",
    "    spectral_centroid = np.sum(freqs * psd_normalized)\n",
    "    \n",
    "    # Spectral bandwidth (spread of frequencies)\n",
    "    spectral_bandwidth = np.sqrt(np.sum(((freqs - spectral_centroid)**2) * psd_normalized))\n",
    "    \n",
    "    # Spectral flatness (noise-like vs tonal)\n",
    "    geometric_mean = np.exp(np.mean(np.log(psd + 1e-10)))\n",
    "    arithmetic_mean = np.mean(psd)\n",
    "    spectral_flatness = geometric_mean / arithmetic_mean if arithmetic_mean > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'rms': rms,\n",
    "        'peak': peak,\n",
    "        'crest_factor': crest_factor,\n",
    "        'zero_crossing_rate': zcr,\n",
    "        'spectral_centroid': spectral_centroid,\n",
    "        'spectral_bandwidth': spectral_bandwidth,\n",
    "        'spectral_flatness': spectral_flatness\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze audio features across lifecycle for sample bearing\n",
    "lifecycle_points = np.linspace(0, 1, 20)  # 20 points across lifecycle\n",
    "feature_evolution = []\n",
    "\n",
    "for pct in lifecycle_points:\n",
    "    file_idx = min(int(num_files * pct), num_files - 1)\n",
    "    sig = signals[file_idx][:, 0]\n",
    "    \n",
    "    features = compute_audio_features(sig)\n",
    "    features['lifecycle_pct'] = pct * 100\n",
    "    features['file_idx'] = file_idx\n",
    "    feature_evolution.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(feature_evolution)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize audio feature evolution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "features_to_plot = [\n",
    "    ('rms', 'RMS (Loudness)', '#3498db'),\n",
    "    ('crest_factor', 'Crest Factor (Impulsiveness)', '#e74c3c'),\n",
    "    ('zero_crossing_rate', 'Zero Crossing Rate (Roughness)', '#2ecc71'),\n",
    "    ('spectral_centroid', 'Spectral Centroid (Brightness)', '#9b59b6'),\n",
    "    ('spectral_bandwidth', 'Spectral Bandwidth (Spread)', '#f39c12'),\n",
    "    ('spectral_flatness', 'Spectral Flatness (Noise-like)', '#1abc9c'),\n",
    "]\n",
    "\n",
    "for ax, (feature, title, color) in zip(axes.flatten(), features_to_plot):\n",
    "    ax.plot(df_features['lifecycle_pct'], df_features[feature], \n",
    "            color=color, linewidth=2, marker='o', markersize=4)\n",
    "    ax.fill_between(df_features['lifecycle_pct'], 0, df_features[feature], \n",
    "                    alpha=0.3, color=color)\n",
    "    ax.set_xlabel('Lifecycle (%)')\n",
    "    ax.set_ylabel(feature.replace('_', ' ').title())\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.axvline(x=80, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Audio Feature Evolution: {sample_bearing}', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Audio Feature Interpretation\n",
    "\n",
    "- **RMS (Loudness)**: Increases significantly toward end-of-life as bearing damage creates louder vibrations\n",
    "- **Crest Factor**: Ratio of peak to RMS; high values indicate impulsive sounds (clicks, impacts)\n",
    "- **Zero Crossing Rate**: Higher values indicate more high-frequency content or roughness\n",
    "- **Spectral Centroid**: Center of mass of spectrum; shifts indicate changes in dominant frequencies\n",
    "- **Spectral Bandwidth**: How spread out the frequencies are; wider = more complex sound\n",
    "- **Spectral Flatness**: Closer to 1 = noise-like; closer to 0 = tonal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Cross-Bearing Audio Comparison\n",
    "\n",
    "Compare audio from healthy states across different bearings to establish baseline, then compare failed states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare healthy vs failed for multiple bearings\n",
    "bearings_to_compare = [\n",
    "    ('35Hz12kN', 'Bearing1_1'),\n",
    "    ('37.5Hz11kN', 'Bearing2_1'),\n",
    "    ('40Hz10kN', 'Bearing3_2'),\n",
    "]\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "for condition, bearing_id in bearings_to_compare:\n",
    "    sigs, fnames = loader.load_bearing(condition, bearing_id)\n",
    "    n_files = len(fnames)\n",
    "    \n",
    "    # Healthy (5%)\n",
    "    healthy_idx = int(n_files * 0.05)\n",
    "    healthy_features = compute_audio_features(sigs[healthy_idx][:, 0])\n",
    "    healthy_features.update({\n",
    "        'condition': condition,\n",
    "        'bearing_id': bearing_id,\n",
    "        'state': 'Healthy'\n",
    "    })\n",
    "    comparison_data.append(healthy_features)\n",
    "    \n",
    "    # Failed (95%)\n",
    "    failed_idx = int(n_files * 0.95)\n",
    "    failed_features = compute_audio_features(sigs[failed_idx][:, 0])\n",
    "    failed_features.update({\n",
    "        'condition': condition,\n",
    "        'bearing_id': bearing_id,\n",
    "        'state': 'Failed'\n",
    "    })\n",
    "    comparison_data.append(failed_features)\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize healthy vs failed comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "features_to_compare = ['rms', 'crest_factor', 'spectral_centroid']\n",
    "colors = {'Healthy': '#2ecc71', 'Failed': '#e74c3c'}\n",
    "\n",
    "for ax, feature in zip(axes, features_to_compare):\n",
    "    # Prepare data for grouped bar chart\n",
    "    x = np.arange(len(bearings_to_compare))\n",
    "    width = 0.35\n",
    "    \n",
    "    healthy_vals = df_comparison[df_comparison['state'] == 'Healthy'][feature].values\n",
    "    failed_vals = df_comparison[df_comparison['state'] == 'Failed'][feature].values\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, healthy_vals, width, label='Healthy', color=colors['Healthy'])\n",
    "    bars2 = ax.bar(x + width/2, failed_vals, width, label='Failed', color=colors['Failed'])\n",
    "    \n",
    "    ax.set_xlabel('Bearing')\n",
    "    ax.set_ylabel(feature.replace('_', ' ').title())\n",
    "    ax.set_title(f'{feature.replace(\"_\", \" \").title()} Comparison', fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([b[1] for b in bearings_to_compare], rotation=15)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Healthy vs Failed: Audio Feature Comparison', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play audio comparison for the bearings\n",
    "print(\"=\"*70)\n",
    "print(\"AUDIO COMPARISON: HEALTHY vs FAILED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for condition, bearing_id in bearings_to_compare:\n",
    "    sigs, fnames = loader.load_bearing(condition, bearing_id)\n",
    "    n_files = len(fnames)\n",
    "    \n",
    "    print(f\"\\n{'-'*50}\")\n",
    "    print(f\"{bearing_id} ({condition})\")\n",
    "    print(f\"{'-'*50}\")\n",
    "    \n",
    "    # Healthy\n",
    "    healthy_idx = int(n_files * 0.05)\n",
    "    healthy_sig = sigs[healthy_idx][:, 0]\n",
    "    healthy_audio = normalize_audio(resample_signal(healthy_sig))\n",
    "    \n",
    "    print(f\"\\nHealthy (5% lifecycle):\")\n",
    "    display(Audio(data=healthy_audio, rate=TARGET_SAMPLE_RATE))\n",
    "    \n",
    "    # Failed\n",
    "    failed_idx = int(n_files * 0.95)\n",
    "    failed_sig = sigs[failed_idx][:, 0]\n",
    "    failed_audio = normalize_audio(resample_signal(failed_sig))\n",
    "    \n",
    "    print(f\"\\nFailed (95% lifecycle):\")\n",
    "    display(Audio(data=failed_audio, rate=TARGET_SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Stereo Audio: Horizontal vs Vertical Channels\n",
    "\n",
    "Listen to both vibration channels simultaneously as stereo audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stereo audio (H=left, V=right)\n",
    "print(\"Stereo Audio: Horizontal (Left) | Vertical (Right)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for stage_name, file_idx in stages.items():\n",
    "    sig = signals[file_idx]  # Both channels\n",
    "    \n",
    "    # Resample both channels\n",
    "    resampled = resample_signal(sig)\n",
    "    stereo_audio = normalize_audio(resampled)\n",
    "    \n",
    "    print(f\"\\n{stage_name} (Stereo):\")\n",
    "    display(Audio(data=stereo_audio.T, rate=TARGET_SAMPLE_RATE))  # Transpose for stereo format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary and Conclusions\n",
    "\n",
    "### Key Findings from Audio Analysis\n",
    "\n",
    "1. **Audible Degradation**: Failed bearings produce distinctly louder and harsher sounds compared to healthy ones\n",
    "\n",
    "2. **RMS as Loudness Indicator**: The RMS value directly correlates with perceived loudness, increasing significantly as bearings degrade\n",
    "\n",
    "3. **Impulsive Sounds**: Crest factor increases near failure, indicating more impulsive/clicking sounds from bearing damage\n",
    "\n",
    "4. **Spectral Changes**: Failed bearings show increased high-frequency content (roughness) and broader spectral bandwidth\n",
    "\n",
    "5. **Cross-Condition Similarity**: Despite different operating conditions (speed/load), the audio characteristics of degradation are qualitatively similar\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "- **Training Data for Acoustic Models**: Generated audio files can train audio-based diagnostic models\n",
    "- **Human-in-the-Loop Inspection**: Sonification allows technicians to \"listen\" to vibration data\n",
    "- **Multimodal Analysis**: Combined audio-visual (spectrogram) analysis improves fault detection\n",
    "- **Educational Tool**: Audio helps build intuition for bearing health states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nEDA-4 Audio Analysis Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nGenerated Audio Files: {len(list(AUDIO_OUTPUT_DIR.glob('*.wav')))}\")\n",
    "print(f\"Output Directory: {AUDIO_OUTPUT_DIR.absolute()}\")\n",
    "print(f\"\\nSampling Rate: {SOURCE_SAMPLE_RATE} Hz -> {TARGET_SAMPLE_RATE} Hz\")\n",
    "print(f\"Signal Duration: {32768/SOURCE_SAMPLE_RATE*1000:.1f} ms per file\")\n",
    "print(f\"\\nCapabilities Demonstrated:\")\n",
    "print(\"  - Vibration to WAV conversion\")\n",
    "print(\"  - 25.6kHz to 44.1kHz resampling\")\n",
    "print(\"  - Audio playback at lifecycle stages\")\n",
    "print(\"  - Interactive audio comparison widget\")\n",
    "print(\"  - Stereo (H/V channels) audio generation\")\n",
    "print(\"  - Audio feature analysis (RMS, ZCR, spectral features)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}