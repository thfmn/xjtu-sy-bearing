# XJTU-SY Bearing RUL Prediction

![Python 3.11+](https://img.shields.io/badge/python-3.11%2B-blue)
![Tests](https://img.shields.io/badge/tests-89%20passed-brightgreen)
![uv](https://img.shields.io/badge/package%20manager-uv-blueviolet)

An MLOps pipeline that predicts the **Remaining Useful Life (RUL)** of rolling element bearings from vibration sensor data. Built on the XJTU-SY benchmark dataset with GCP infrastructure for data processing, model training, and experiment tracking.

## The Problem

Bearings are among the most critical â€” and most failure-prone â€” components in rotating machinery. A single unexpected bearing failure in a wind turbine, industrial pump, or rail axle can halt production for days and cost tens of thousands of dollars.

Traditional maintenance strategies are either **reactive** (fix it when it breaks â€” expensive downtime) or **time-based** (replace on a schedule â€” wastes perfectly good parts). **Predictive maintenance** uses sensor data to estimate how much useful life remains, enabling repairs at exactly the right time.

This project takes raw vibration signals from accelerometers mounted on bearings and predicts how many minutes of operation remain before failure â€” the **Remaining Useful Life**.

## Architecture Overview

```
Raw Vibration CSVs (25.6 kHz, 2-channel)
    â”‚
    â”œâ”€â†’ Feature Extraction (65 features)  â”€â†’  LightGBM  â”€â†’  RUL Prediction
    â”‚
    â”œâ”€â†’ 1D Signal Windowing (32768Ã—2)     â”€â†’  1D CNN / TCN-Transformer  â”€â†’  RUL
    â”‚
    â””â”€â†’ STFT Spectrograms (128Ã—128Ã—2)     â”€â†’  2D CNN / CNN-LSTM  â”€â†’  RUL
```

Three parallel input representations feed different model families â€” from gradient-boosted trees on hand-crafted features to deep learning on raw signals and spectrograms.

## Dataset

**XJTU-SY Bearing Dataset** â€” a widely-used benchmark for bearing prognostics research.

| Property | Value |
|---|---|
| Bearings | 15 (run-to-failure) |
| Operating conditions | 3 (35 Hz/12 kN, 37.5 Hz/11 kN, 40 Hz/10 kN) |
| Sampling rate | 25.6 kHz |
| Channels | 2 (horizontal + vertical vibration) |
| Total files | ~9,216 |

Each CSV file contains 32,768 samples (1.28 s recording) captured at regular intervals throughout a bearing's lifetime.

## Models

Five architectures are registered in the model registry (`src/models/registry.py`):

| Model | Input Type | Input Shape | Architecture |
|---|---|---|---|
| **LightGBM** | 65 features | tabular | Gradient-boosted trees (baseline) |
| **1D CNN** | Raw signal | 32768 Ã— 2 | Conv1D â†’ BatchNorm â†’ GlobalAvgPool â†’ Dense |
| **TCN-Transformer** | Raw signal | 32768 Ã— 2 | Temporal conv + multi-head attention |
| **Pattern2 Simple** | Spectrogram | 128 Ã— 128 Ã— 2 | 2D CNN with progressive downsampling |
| **Pattern2 LSTM** | Spectrogram | 128 Ã— 128 Ã— 2 | 2D CNN encoder â†’ LSTM sequence head |

## Results

| Model | RMSE | MAE | Evaluation | Status |
|---|---|---|---|---|
| LightGBM | 22.43 | 14.84 | 15-fold CV | âœ… Complete |
| 1D CNN | 17.52 | 14.22 | Fold 0 | âœ… Complete |
| Pattern2 2D CNN | 14.39 | 12.15 | Fold 0 | âœ… Complete |
| TCN-Transformer | â€” | â€” | â€” | ðŸ”„ Training |

> **Note:** Deep learning models show fold-0 results only; full 15-fold leave-one-bearing-out evaluation is pending. RMSE/MAE are in percentage of total lifetime.

## Quick Start

```bash
# Install dependencies (requires uv: https://docs.astral.sh/uv/)
uv sync

# Run tests
uv run pytest tests/

# Train a model (e.g., 1D CNN baseline, fold 0)
python scripts/05_train_dl_models.py --model cnn1d_baseline --folds 0

# Train with a specific config
python scripts/05_train_dl_models.py --model pattern2_simple --config configs/pattern2_cnn2d.yaml

# Evaluate trained models
python scripts/06_evaluate_dl_models.py

# Launch experiment tracking UI
bash scripts/mlflow_server.sh
```

## Project Structure

```
â”œâ”€â”€ configs/                  # YAML training configurations
â”‚   â”œâ”€â”€ cnn1d_baseline.yaml
â”‚   â”œâ”€â”€ pattern2_cnn2d.yaml
â”‚   â”œâ”€â”€ tcn_transformer.yaml
â”‚   â””â”€â”€ training_default.yaml
â”œâ”€â”€ notebooks/                # EDA, training, and evaluation notebooks
â”‚   â”œâ”€â”€ 01-03_eda_*.ipynb     #   Exploratory data analysis
â”‚   â”œâ”€â”€ 20-24_model_*.ipynb   #   Model development
â”‚   â””â”€â”€ 30_evaluation.ipynb   #   Cross-model comparison
â”œâ”€â”€ scripts/                  # Pipeline scripts (numbered by stage)
â”‚   â”œâ”€â”€ 01_upload_to_gcs_with_hive_partitioning.py
â”‚   â”œâ”€â”€ 02_preprocessing.py
â”‚   â”œâ”€â”€ 03_extract_features.py
â”‚   â”œâ”€â”€ 04_generate_spectrograms.py
â”‚   â”œâ”€â”€ 05_train_dl_models.py
â”‚   â””â”€â”€ 06_evaluate_dl_models.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                 # Data loading, windowing, RUL labels
â”‚   â”œâ”€â”€ features/             # 65-feature extraction (time + frequency domain)
â”‚   â”œâ”€â”€ models/               # Model registry and architectures
â”‚   â”‚   â”œâ”€â”€ baselines/        #   LightGBM, 1D CNN
â”‚   â”‚   â”œâ”€â”€ pattern1/         #   TCN-Transformer variants
â”‚   â”‚   â””â”€â”€ pattern2/         #   Spectrogram-based (2D CNN, CNN-LSTM)
â”‚   â”œâ”€â”€ training/             # Config, cross-validation, metrics
â”‚   â””â”€â”€ utils/                # Experiment tracking, helpers
â”œâ”€â”€ tests/                    # pytest suite (89 tests)
â””â”€â”€ pyproject.toml
```

## Experiment Tracking

Dual-backend setup for local development and cloud reproducibility:

- **MLflow** (local) â€” `bash scripts/mlflow_server.sh` launches the UI at `localhost:5000`
- **Vertex AI Experiments** (cloud) â€” automatic logging when running on GCP with `--tracking vertex`

## Tech Stack

- **ML Frameworks:** TensorFlow/Keras, PyTorch, LightGBM
- **Signal Processing:** SciPy, PyWavelets
- **Data:** Pandas, NumPy, BigQuery
- **Infrastructure:** GCS, Vertex AI, MLflow
- **Package Management:** uv
- **Visualization:** Seaborn, Plotly, Gradio (demo UI)
